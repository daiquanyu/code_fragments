{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6465, 5000)\n",
      "(6465, 2)\n",
      "(5586, 5000)\n",
      "(5586, 2)\n",
      "(7681, 5000)\n",
      "(7681, 2)\n",
      "(7945, 5000)\n",
      "(7945, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "\n",
    "datasets = ['books', 'dvd', 'electronics', 'kitchen']\n",
    "\n",
    "for dataset in datasets:\n",
    "    attrb = []\n",
    "    group = []\n",
    "    \n",
    "    # training file\n",
    "    fid = open('{}_train.svmlight'.format(dataset), 'r')\n",
    "    line = fid.readline().strip()\n",
    "    while line:\n",
    "        line = line.split()\n",
    "        label = int(line[0])\n",
    "        label = [1, 0] if label==1 else [0, 1]\n",
    "        bag_of_words = np.zeros((1, 5000))\n",
    "        for j in range(len(line)-1):\n",
    "            word_freq = line[j+1].split(':')\n",
    "            bag_of_words[0, int(word_freq[0])] = int(word_freq[1])\n",
    "        attrb.append(bag_of_words)\n",
    "        group.append(label)\n",
    "        line = fid.readline().strip()\n",
    "    fid.close()\n",
    "        \n",
    "    # testing file\n",
    "    fid = open('{}_test.svmlight'.format(dataset), 'r')\n",
    "    line = fid.readline().strip()\n",
    "    while line:\n",
    "        line = line.split()\n",
    "        label = int(line[0])\n",
    "        label = [1, 0] if label==1 else [0, 1]\n",
    "        bag_of_words = np.zeros((1, 5000))\n",
    "        for j in range(len(line)-1):\n",
    "            word_freq = line[j+1].split(':')\n",
    "            bag_of_words[0, int(word_freq[0])] = int(word_freq[1])\n",
    "        attrb.append(bag_of_words)\n",
    "        group.append(label)\n",
    "        line = fid.readline().strip()\n",
    "    fid.close()\n",
    "    \n",
    "    attrb = np.concatenate(attrb, axis=0)\n",
    "    group = np.array(group)\n",
    "    \n",
    "    print(attrb.shape)\n",
    "    print(group.shape)\n",
    "    \n",
    "    sio.savemat('{}.mat'.format(dataset), {'attrb': attrb, 'group': group})\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t6.0\n",
      "  (0, 1)\t8.0\n",
      "  (0, 2)\t8.0\n",
      "  (0, 3)\t2.0\n",
      "  (0, 4)\t3.0\n",
      "  (0, 6)\t5.0\n",
      "  (0, 7)\t3.0\n",
      "  (0, 8)\t3.0\n",
      "  (0, 9)\t1.0\n",
      "  (0, 10)\t6.0\n",
      "  (0, 12)\t2.0\n",
      "  (0, 13)\t1.0\n",
      "  (0, 14)\t1.0\n",
      "  (0, 16)\t2.0\n",
      "  (0, 17)\t4.0\n",
      "  (0, 19)\t8.0\n",
      "  (0, 20)\t2.0\n",
      "  (0, 21)\t1.0\n",
      "  (0, 22)\t4.0\n",
      "  (0, 23)\t1.0\n",
      "  (0, 24)\t1.0\n",
      "  (0, 25)\t2.0\n",
      "  (0, 27)\t1.0\n",
      "  (0, 28)\t1.0\n",
      "  (0, 29)\t1.0\n",
      "  :\t:\n",
      "  (0, 3960)\t1.0\n",
      "  (0, 3996)\t1.0\n",
      "  (0, 4225)\t1.0\n",
      "  (0, 4261)\t1.0\n",
      "  (0, 4297)\t1.0\n",
      "  (0, 4304)\t2.0\n",
      "  (0, 4308)\t1.0\n",
      "  (0, 4362)\t1.0\n",
      "  (0, 4363)\t1.0\n",
      "  (0, 4379)\t1.0\n",
      "  (0, 4380)\t1.0\n",
      "  (0, 4398)\t1.0\n",
      "  (0, 4439)\t1.0\n",
      "  (0, 4440)\t1.0\n",
      "  (0, 4444)\t1.0\n",
      "  (0, 4464)\t3.0\n",
      "  (0, 4465)\t1.0\n",
      "  (0, 4473)\t1.0\n",
      "  (0, 4551)\t1.0\n",
      "  (0, 4570)\t1.0\n",
      "  (0, 4655)\t1.0\n",
      "  (0, 4697)\t1.0\n",
      "  (0, 4939)\t1.0\n",
      "  (0, 4949)\t1.0\n",
      "  (0, 4962)\t1.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csc_matrix\n",
    "\n",
    "attrb = sio.loadmat('books.mat')['attrb']\n",
    "attrb = csc_matrix(attrb)\n",
    "\n",
    "print(attrb[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "[2 4]\n",
      "[[0.5  1.  ]\n",
      " [0.75 1.  ]]\n",
      "1.3862943611198906\n",
      "[[1 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[1, 2], [3 ,4]])\n",
    "print(A)\n",
    "print(np.max(A, 1))\n",
    "most_freq = np.concatenate([np.reshape(1/np.max(A, 1), (-1, 1))]*A.shape[1], axis=1)\n",
    "A = np.multiply(A, most_freq)\n",
    "\n",
    "print(A)\n",
    "\n",
    "print(np.log(4))\n",
    "\n",
    "print(np.array(A>0, np.int32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Graph Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3]\n",
      "Hi\n",
      "[0 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[0, 0], [3, 0]])\n",
    "B = np.max(A, 1)\n",
    "print(B)\n",
    "if (B<0.001).any():\n",
    "    print('Hi')\n",
    "\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in multiply\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-858834c41754>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mTF_IDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIDF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkneighbors_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTF_IDF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'connectivity'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cosine'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_self\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsc_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/neighbors/graph.py\u001b[0m in \u001b[0;36mkneighbors_graph\u001b[0;34m(X, n_neighbors, mode, metric, p, metric_params, include_self, n_jobs)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKNeighborsMixin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         X = NearestNeighbors(n_neighbors, metric=metric, p=p,\n\u001b[0;32m---> 98\u001b[0;31m                              metric_params=metric_params, n_jobs=n_jobs).fit(X)\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'precomputed'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m         \"\"\"\n\u001b[0;32m--> 803\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    451\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 44\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csc_matrix\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "datasets = ['electronics', 'books']\n",
    "\n",
    "for dataset in datasets:\n",
    "    attrb = sio.loadmat('{}.mat'.format(dataset))['attrb']\n",
    "    group = sio.loadmat('{}.mat'.format(dataset))['group']\n",
    "\n",
    "    max_freq = np.max(attrb, 1)\n",
    "    max_freq[np.where(max_freq==0)] = 1\n",
    "    most_freq = np.concatenate([np.reshape(1/max_freq, (-1, 1))]*attrb.shape[1], axis=1)\n",
    "    TF = np.multiply(attrb, most_freq)\n",
    "\n",
    "    IDF = np.log(attrb.shape[0]/(np.sum(np.array(attrb>0.01, np.int32), axis=0)+1))\n",
    "    IDF = np.concatenate([np.reshape(IDF, (1, -1))]*attrb.shape[0], axis=0)\n",
    "\n",
    "    TF_IDF = np.multiply(TF, IDF)\n",
    "    network = kneighbors_graph(TF_IDF, 5, mode='connectivity', metric='cosine', include_self=False)\n",
    "\n",
    "    network = csc_matrix(network)\n",
    "    attrb = csc_matrix(attrb)\n",
    "\n",
    "    print(dataset)\n",
    "    print(network.shape)\n",
    "    print(attrb.shape)\n",
    "    print(group.shape)\n",
    "\n",
    "    sio.savemat('{}.mat'.format(dataset), {'network': network, 'group': group, 'attrb': attrb})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
